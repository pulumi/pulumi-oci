// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Oci.GenerativeAi.Inputs
{

    public sealed class ModelFineTuneDetailsTrainingConfigArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Stop training if the loss metric does not improve beyond 'early_stopping_threshold' for this many times of evaluation.
        /// </summary>
        [Input("earlyStoppingPatience")]
        public Input<int>? EarlyStoppingPatience { get; set; }

        /// <summary>
        /// How much the loss must improve to prevent early stopping.
        /// </summary>
        [Input("earlyStoppingThreshold")]
        public Input<double>? EarlyStoppingThreshold { get; set; }

        /// <summary>
        /// The initial learning rate to be used during training
        /// </summary>
        [Input("learningRate")]
        public Input<double>? LearningRate { get; set; }

        /// <summary>
        /// Determines how frequently to log model metrics. 
        /// 
        /// Every step is logged for the first 20 steps and then follows this parameter for log frequency. Set to 0 to disable logging the model metrics.
        /// </summary>
        [Input("logModelMetricsIntervalInSteps")]
        public Input<int>? LogModelMetricsIntervalInSteps { get; set; }

        /// <summary>
        /// This parameter represents the scaling factor for the weight matrices in LoRA.
        /// </summary>
        [Input("loraAlpha")]
        public Input<int>? LoraAlpha { get; set; }

        /// <summary>
        /// This parameter indicates the dropout probability for LoRA layers.
        /// </summary>
        [Input("loraDropout")]
        public Input<double>? LoraDropout { get; set; }

        /// <summary>
        /// This parameter represents the LoRA rank of the update matrices.
        /// </summary>
        [Input("loraR")]
        public Input<int>? LoraR { get; set; }

        /// <summary>
        /// The number of last layers to be fine-tuned.
        /// </summary>
        [Input("numOfLastLayers")]
        public Input<int>? NumOfLastLayers { get; set; }

        /// <summary>
        /// The maximum number of training epochs to run for.
        /// </summary>
        [Input("totalTrainingEpochs")]
        public Input<int>? TotalTrainingEpochs { get; set; }

        /// <summary>
        /// The batch size used during training.
        /// </summary>
        [Input("trainingBatchSize")]
        public Input<int>? TrainingBatchSize { get; set; }

        /// <summary>
        /// The fine-tuning method for training a custom model.
        /// </summary>
        [Input("trainingConfigType", required: true)]
        public Input<string> TrainingConfigType { get; set; } = null!;

        public ModelFineTuneDetailsTrainingConfigArgs()
        {
        }
        public static new ModelFineTuneDetailsTrainingConfigArgs Empty => new ModelFineTuneDetailsTrainingConfigArgs();
    }
}
