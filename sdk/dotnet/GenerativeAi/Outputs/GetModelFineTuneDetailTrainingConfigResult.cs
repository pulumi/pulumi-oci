// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Oci.GenerativeAi.Outputs
{

    [OutputType]
    public sealed class GetModelFineTuneDetailTrainingConfigResult
    {
        /// <summary>
        /// Stop training if the loss metric does not improve beyond 'early_stopping_threshold' for this many times of evaluation.
        /// </summary>
        public readonly int EarlyStoppingPatience;
        /// <summary>
        /// How much the loss must improve to prevent early stopping.
        /// </summary>
        public readonly double EarlyStoppingThreshold;
        /// <summary>
        /// The initial learning rate to be used during training
        /// </summary>
        public readonly double LearningRate;
        /// <summary>
        /// Determines how frequently to log model metrics.
        /// </summary>
        public readonly int LogModelMetricsIntervalInSteps;
        /// <summary>
        /// This parameter represents the scaling factor for the weight matrices in LoRA.
        /// </summary>
        public readonly int LoraAlpha;
        /// <summary>
        /// This parameter indicates the dropout probability for LoRA layers.
        /// </summary>
        public readonly double LoraDropout;
        /// <summary>
        /// This parameter represents the LoRA rank of the update matrices.
        /// </summary>
        public readonly int LoraR;
        /// <summary>
        /// The number of last layers to be fine-tuned.
        /// </summary>
        public readonly int NumOfLastLayers;
        /// <summary>
        /// The maximum number of training epochs to run for.
        /// </summary>
        public readonly int TotalTrainingEpochs;
        /// <summary>
        /// The batch size used during training.
        /// </summary>
        public readonly int TrainingBatchSize;
        /// <summary>
        /// The fine-tuning method for training a custom model.
        /// </summary>
        public readonly string TrainingConfigType;

        [OutputConstructor]
        private GetModelFineTuneDetailTrainingConfigResult(
            int earlyStoppingPatience,

            double earlyStoppingThreshold,

            double learningRate,

            int logModelMetricsIntervalInSteps,

            int loraAlpha,

            double loraDropout,

            int loraR,

            int numOfLastLayers,

            int totalTrainingEpochs,

            int trainingBatchSize,

            string trainingConfigType)
        {
            EarlyStoppingPatience = earlyStoppingPatience;
            EarlyStoppingThreshold = earlyStoppingThreshold;
            LearningRate = learningRate;
            LogModelMetricsIntervalInSteps = logModelMetricsIntervalInSteps;
            LoraAlpha = loraAlpha;
            LoraDropout = loraDropout;
            LoraR = loraR;
            NumOfLastLayers = numOfLastLayers;
            TotalTrainingEpochs = totalTrainingEpochs;
            TrainingBatchSize = trainingBatchSize;
            TrainingConfigType = trainingConfigType;
        }
    }
}
