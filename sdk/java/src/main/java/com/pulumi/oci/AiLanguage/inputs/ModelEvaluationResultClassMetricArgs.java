// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.oci.AiLanguage.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import java.lang.Double;
import java.lang.String;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class ModelEvaluationResultClassMetricArgs extends com.pulumi.resources.ResourceArgs {

    public static final ModelEvaluationResultClassMetricArgs Empty = new ModelEvaluationResultClassMetricArgs();

    /**
     * F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    @Import(name="f1")
    private @Nullable Output<Double> f1;

    /**
     * @return F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    public Optional<Output<Double>> f1() {
        return Optional.ofNullable(this.f1);
    }

    /**
     * Entity label
     * 
     */
    @Import(name="label")
    private @Nullable Output<String> label;

    /**
     * @return Entity label
     * 
     */
    public Optional<Output<String>> label() {
        return Optional.ofNullable(this.label);
    }

    /**
     * Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    @Import(name="precision")
    private @Nullable Output<Double> precision;

    /**
     * @return Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    public Optional<Output<Double>> precision() {
        return Optional.ofNullable(this.precision);
    }

    /**
     * Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    @Import(name="recall")
    private @Nullable Output<Double> recall;

    /**
     * @return Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    public Optional<Output<Double>> recall() {
        return Optional.ofNullable(this.recall);
    }

    /**
     * number of samples in the test set
     * 
     */
    @Import(name="support")
    private @Nullable Output<Double> support;

    /**
     * @return number of samples in the test set
     * 
     */
    public Optional<Output<Double>> support() {
        return Optional.ofNullable(this.support);
    }

    private ModelEvaluationResultClassMetricArgs() {}

    private ModelEvaluationResultClassMetricArgs(ModelEvaluationResultClassMetricArgs $) {
        this.f1 = $.f1;
        this.label = $.label;
        this.precision = $.precision;
        this.recall = $.recall;
        this.support = $.support;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(ModelEvaluationResultClassMetricArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private ModelEvaluationResultClassMetricArgs $;

        public Builder() {
            $ = new ModelEvaluationResultClassMetricArgs();
        }

        public Builder(ModelEvaluationResultClassMetricArgs defaults) {
            $ = new ModelEvaluationResultClassMetricArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param f1 F1-score, is a measure of a model’s accuracy on a dataset
         * 
         * @return builder
         * 
         */
        public Builder f1(@Nullable Output<Double> f1) {
            $.f1 = f1;
            return this;
        }

        /**
         * @param f1 F1-score, is a measure of a model’s accuracy on a dataset
         * 
         * @return builder
         * 
         */
        public Builder f1(Double f1) {
            return f1(Output.of(f1));
        }

        /**
         * @param label Entity label
         * 
         * @return builder
         * 
         */
        public Builder label(@Nullable Output<String> label) {
            $.label = label;
            return this;
        }

        /**
         * @param label Entity label
         * 
         * @return builder
         * 
         */
        public Builder label(String label) {
            return label(Output.of(label));
        }

        /**
         * @param precision Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
         * 
         * @return builder
         * 
         */
        public Builder precision(@Nullable Output<Double> precision) {
            $.precision = precision;
            return this;
        }

        /**
         * @param precision Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
         * 
         * @return builder
         * 
         */
        public Builder precision(Double precision) {
            return precision(Output.of(precision));
        }

        /**
         * @param recall Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
         * 
         * @return builder
         * 
         */
        public Builder recall(@Nullable Output<Double> recall) {
            $.recall = recall;
            return this;
        }

        /**
         * @param recall Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
         * 
         * @return builder
         * 
         */
        public Builder recall(Double recall) {
            return recall(Output.of(recall));
        }

        /**
         * @param support number of samples in the test set
         * 
         * @return builder
         * 
         */
        public Builder support(@Nullable Output<Double> support) {
            $.support = support;
            return this;
        }

        /**
         * @param support number of samples in the test set
         * 
         * @return builder
         * 
         */
        public Builder support(Double support) {
            return support(Output.of(support));
        }

        public ModelEvaluationResultClassMetricArgs build() {
            return $;
        }
    }

}
