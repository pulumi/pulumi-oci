// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.oci.AiLanguage.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Double;
import java.lang.String;
import java.util.Objects;

@CustomType
public final class GetModelsModelCollectionItemEvaluationResultClassMetric {
    /**
     * @return F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    private Double f1;
    /**
     * @return Entity label
     * 
     */
    private String label;
    /**
     * @return Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    private Double precision;
    /**
     * @return Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    private Double recall;
    /**
     * @return number of samples in the test set
     * 
     */
    private Double support;

    private GetModelsModelCollectionItemEvaluationResultClassMetric() {}
    /**
     * @return F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    public Double f1() {
        return this.f1;
    }
    /**
     * @return Entity label
     * 
     */
    public String label() {
        return this.label;
    }
    /**
     * @return Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    public Double precision() {
        return this.precision;
    }
    /**
     * @return Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    public Double recall() {
        return this.recall;
    }
    /**
     * @return number of samples in the test set
     * 
     */
    public Double support() {
        return this.support;
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(GetModelsModelCollectionItemEvaluationResultClassMetric defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private Double f1;
        private String label;
        private Double precision;
        private Double recall;
        private Double support;
        public Builder() {}
        public Builder(GetModelsModelCollectionItemEvaluationResultClassMetric defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.f1 = defaults.f1;
    	      this.label = defaults.label;
    	      this.precision = defaults.precision;
    	      this.recall = defaults.recall;
    	      this.support = defaults.support;
        }

        @CustomType.Setter
        public Builder f1(Double f1) {
            if (f1 == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultClassMetric", "f1");
            }
            this.f1 = f1;
            return this;
        }
        @CustomType.Setter
        public Builder label(String label) {
            if (label == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultClassMetric", "label");
            }
            this.label = label;
            return this;
        }
        @CustomType.Setter
        public Builder precision(Double precision) {
            if (precision == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultClassMetric", "precision");
            }
            this.precision = precision;
            return this;
        }
        @CustomType.Setter
        public Builder recall(Double recall) {
            if (recall == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultClassMetric", "recall");
            }
            this.recall = recall;
            return this;
        }
        @CustomType.Setter
        public Builder support(Double support) {
            if (support == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultClassMetric", "support");
            }
            this.support = support;
            return this;
        }
        public GetModelsModelCollectionItemEvaluationResultClassMetric build() {
            final var _resultValue = new GetModelsModelCollectionItemEvaluationResultClassMetric();
            _resultValue.f1 = f1;
            _resultValue.label = label;
            _resultValue.precision = precision;
            _resultValue.recall = recall;
            _resultValue.support = support;
            return _resultValue;
        }
    }
}
