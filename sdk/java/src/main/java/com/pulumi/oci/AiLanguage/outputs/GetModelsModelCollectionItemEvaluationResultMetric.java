// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.oci.AiLanguage.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Double;
import java.util.Objects;

@CustomType
public final class GetModelsModelCollectionItemEvaluationResultMetric {
    /**
     * @return The fraction of the labels that were correctly recognised .
     * 
     */
    private Double accuracy;
    /**
     * @return F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    private Double macroF1;
    /**
     * @return Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    private Double macroPrecision;
    /**
     * @return Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    private Double macroRecall;
    /**
     * @return F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    private Double microF1;
    /**
     * @return Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    private Double microPrecision;
    /**
     * @return Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    private Double microRecall;
    /**
     * @return F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    private Double weightedF1;
    /**
     * @return Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    private Double weightedPrecision;
    /**
     * @return Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    private Double weightedRecall;

    private GetModelsModelCollectionItemEvaluationResultMetric() {}
    /**
     * @return The fraction of the labels that were correctly recognised .
     * 
     */
    public Double accuracy() {
        return this.accuracy;
    }
    /**
     * @return F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    public Double macroF1() {
        return this.macroF1;
    }
    /**
     * @return Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    public Double macroPrecision() {
        return this.macroPrecision;
    }
    /**
     * @return Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    public Double macroRecall() {
        return this.macroRecall;
    }
    /**
     * @return F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    public Double microF1() {
        return this.microF1;
    }
    /**
     * @return Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    public Double microPrecision() {
        return this.microPrecision;
    }
    /**
     * @return Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    public Double microRecall() {
        return this.microRecall;
    }
    /**
     * @return F1-score, is a measure of a model’s accuracy on a dataset
     * 
     */
    public Double weightedF1() {
        return this.weightedF1;
    }
    /**
     * @return Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives)
     * 
     */
    public Double weightedPrecision() {
        return this.weightedPrecision;
    }
    /**
     * @return Measures the model&#39;s ability to predict actual positive classes. It is the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.
     * 
     */
    public Double weightedRecall() {
        return this.weightedRecall;
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(GetModelsModelCollectionItemEvaluationResultMetric defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private Double accuracy;
        private Double macroF1;
        private Double macroPrecision;
        private Double macroRecall;
        private Double microF1;
        private Double microPrecision;
        private Double microRecall;
        private Double weightedF1;
        private Double weightedPrecision;
        private Double weightedRecall;
        public Builder() {}
        public Builder(GetModelsModelCollectionItemEvaluationResultMetric defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.accuracy = defaults.accuracy;
    	      this.macroF1 = defaults.macroF1;
    	      this.macroPrecision = defaults.macroPrecision;
    	      this.macroRecall = defaults.macroRecall;
    	      this.microF1 = defaults.microF1;
    	      this.microPrecision = defaults.microPrecision;
    	      this.microRecall = defaults.microRecall;
    	      this.weightedF1 = defaults.weightedF1;
    	      this.weightedPrecision = defaults.weightedPrecision;
    	      this.weightedRecall = defaults.weightedRecall;
        }

        @CustomType.Setter
        public Builder accuracy(Double accuracy) {
            if (accuracy == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "accuracy");
            }
            this.accuracy = accuracy;
            return this;
        }
        @CustomType.Setter
        public Builder macroF1(Double macroF1) {
            if (macroF1 == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "macroF1");
            }
            this.macroF1 = macroF1;
            return this;
        }
        @CustomType.Setter
        public Builder macroPrecision(Double macroPrecision) {
            if (macroPrecision == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "macroPrecision");
            }
            this.macroPrecision = macroPrecision;
            return this;
        }
        @CustomType.Setter
        public Builder macroRecall(Double macroRecall) {
            if (macroRecall == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "macroRecall");
            }
            this.macroRecall = macroRecall;
            return this;
        }
        @CustomType.Setter
        public Builder microF1(Double microF1) {
            if (microF1 == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "microF1");
            }
            this.microF1 = microF1;
            return this;
        }
        @CustomType.Setter
        public Builder microPrecision(Double microPrecision) {
            if (microPrecision == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "microPrecision");
            }
            this.microPrecision = microPrecision;
            return this;
        }
        @CustomType.Setter
        public Builder microRecall(Double microRecall) {
            if (microRecall == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "microRecall");
            }
            this.microRecall = microRecall;
            return this;
        }
        @CustomType.Setter
        public Builder weightedF1(Double weightedF1) {
            if (weightedF1 == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "weightedF1");
            }
            this.weightedF1 = weightedF1;
            return this;
        }
        @CustomType.Setter
        public Builder weightedPrecision(Double weightedPrecision) {
            if (weightedPrecision == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "weightedPrecision");
            }
            this.weightedPrecision = weightedPrecision;
            return this;
        }
        @CustomType.Setter
        public Builder weightedRecall(Double weightedRecall) {
            if (weightedRecall == null) {
              throw new MissingRequiredPropertyException("GetModelsModelCollectionItemEvaluationResultMetric", "weightedRecall");
            }
            this.weightedRecall = weightedRecall;
            return this;
        }
        public GetModelsModelCollectionItemEvaluationResultMetric build() {
            final var _resultValue = new GetModelsModelCollectionItemEvaluationResultMetric();
            _resultValue.accuracy = accuracy;
            _resultValue.macroF1 = macroF1;
            _resultValue.macroPrecision = macroPrecision;
            _resultValue.macroRecall = macroRecall;
            _resultValue.microF1 = microF1;
            _resultValue.microPrecision = microPrecision;
            _resultValue.microRecall = microRecall;
            _resultValue.weightedF1 = weightedF1;
            _resultValue.weightedPrecision = weightedPrecision;
            _resultValue.weightedRecall = weightedRecall;
            return _resultValue;
        }
    }
}
