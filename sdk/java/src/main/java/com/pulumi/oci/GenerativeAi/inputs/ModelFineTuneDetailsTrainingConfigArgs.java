// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.oci.GenerativeAi.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class ModelFineTuneDetailsTrainingConfigArgs extends com.pulumi.resources.ResourceArgs {

    public static final ModelFineTuneDetailsTrainingConfigArgs Empty = new ModelFineTuneDetailsTrainingConfigArgs();

    /**
     * Stop training if the loss metric does not improve beyond &#39;early_stopping_threshold&#39; for this many times of evaluation.
     * 
     */
    @Import(name="earlyStoppingPatience")
    private @Nullable Output<Integer> earlyStoppingPatience;

    /**
     * @return Stop training if the loss metric does not improve beyond &#39;early_stopping_threshold&#39; for this many times of evaluation.
     * 
     */
    public Optional<Output<Integer>> earlyStoppingPatience() {
        return Optional.ofNullable(this.earlyStoppingPatience);
    }

    /**
     * How much the loss must improve to prevent early stopping.
     * 
     */
    @Import(name="earlyStoppingThreshold")
    private @Nullable Output<Double> earlyStoppingThreshold;

    /**
     * @return How much the loss must improve to prevent early stopping.
     * 
     */
    public Optional<Output<Double>> earlyStoppingThreshold() {
        return Optional.ofNullable(this.earlyStoppingThreshold);
    }

    /**
     * The initial learning rate to be used during training
     * 
     */
    @Import(name="learningRate")
    private @Nullable Output<Double> learningRate;

    /**
     * @return The initial learning rate to be used during training
     * 
     */
    public Optional<Output<Double>> learningRate() {
        return Optional.ofNullable(this.learningRate);
    }

    /**
     * Determines how frequently to log model metrics.
     * 
     * Every step is logged for the first 20 steps and then follows this parameter for log frequency. Set to 0 to disable logging the model metrics.
     * 
     */
    @Import(name="logModelMetricsIntervalInSteps")
    private @Nullable Output<Integer> logModelMetricsIntervalInSteps;

    /**
     * @return Determines how frequently to log model metrics.
     * 
     * Every step is logged for the first 20 steps and then follows this parameter for log frequency. Set to 0 to disable logging the model metrics.
     * 
     */
    public Optional<Output<Integer>> logModelMetricsIntervalInSteps() {
        return Optional.ofNullable(this.logModelMetricsIntervalInSteps);
    }

    /**
     * This parameter represents the scaling factor for the weight matrices in LoRA.
     * 
     */
    @Import(name="loraAlpha")
    private @Nullable Output<Integer> loraAlpha;

    /**
     * @return This parameter represents the scaling factor for the weight matrices in LoRA.
     * 
     */
    public Optional<Output<Integer>> loraAlpha() {
        return Optional.ofNullable(this.loraAlpha);
    }

    /**
     * This parameter indicates the dropout probability for LoRA layers.
     * 
     */
    @Import(name="loraDropout")
    private @Nullable Output<Double> loraDropout;

    /**
     * @return This parameter indicates the dropout probability for LoRA layers.
     * 
     */
    public Optional<Output<Double>> loraDropout() {
        return Optional.ofNullable(this.loraDropout);
    }

    /**
     * This parameter represents the LoRA rank of the update matrices.
     * 
     */
    @Import(name="loraR")
    private @Nullable Output<Integer> loraR;

    /**
     * @return This parameter represents the LoRA rank of the update matrices.
     * 
     */
    public Optional<Output<Integer>> loraR() {
        return Optional.ofNullable(this.loraR);
    }

    /**
     * The number of last layers to be fine-tuned.
     * 
     */
    @Import(name="numOfLastLayers")
    private @Nullable Output<Integer> numOfLastLayers;

    /**
     * @return The number of last layers to be fine-tuned.
     * 
     */
    public Optional<Output<Integer>> numOfLastLayers() {
        return Optional.ofNullable(this.numOfLastLayers);
    }

    /**
     * The maximum number of training epochs to run for.
     * 
     */
    @Import(name="totalTrainingEpochs")
    private @Nullable Output<Integer> totalTrainingEpochs;

    /**
     * @return The maximum number of training epochs to run for.
     * 
     */
    public Optional<Output<Integer>> totalTrainingEpochs() {
        return Optional.ofNullable(this.totalTrainingEpochs);
    }

    /**
     * The batch size used during training.
     * 
     */
    @Import(name="trainingBatchSize")
    private @Nullable Output<Integer> trainingBatchSize;

    /**
     * @return The batch size used during training.
     * 
     */
    public Optional<Output<Integer>> trainingBatchSize() {
        return Optional.ofNullable(this.trainingBatchSize);
    }

    /**
     * The fine-tuning method for training a custom model.
     * 
     */
    @Import(name="trainingConfigType", required=true)
    private Output<String> trainingConfigType;

    /**
     * @return The fine-tuning method for training a custom model.
     * 
     */
    public Output<String> trainingConfigType() {
        return this.trainingConfigType;
    }

    private ModelFineTuneDetailsTrainingConfigArgs() {}

    private ModelFineTuneDetailsTrainingConfigArgs(ModelFineTuneDetailsTrainingConfigArgs $) {
        this.earlyStoppingPatience = $.earlyStoppingPatience;
        this.earlyStoppingThreshold = $.earlyStoppingThreshold;
        this.learningRate = $.learningRate;
        this.logModelMetricsIntervalInSteps = $.logModelMetricsIntervalInSteps;
        this.loraAlpha = $.loraAlpha;
        this.loraDropout = $.loraDropout;
        this.loraR = $.loraR;
        this.numOfLastLayers = $.numOfLastLayers;
        this.totalTrainingEpochs = $.totalTrainingEpochs;
        this.trainingBatchSize = $.trainingBatchSize;
        this.trainingConfigType = $.trainingConfigType;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(ModelFineTuneDetailsTrainingConfigArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private ModelFineTuneDetailsTrainingConfigArgs $;

        public Builder() {
            $ = new ModelFineTuneDetailsTrainingConfigArgs();
        }

        public Builder(ModelFineTuneDetailsTrainingConfigArgs defaults) {
            $ = new ModelFineTuneDetailsTrainingConfigArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param earlyStoppingPatience Stop training if the loss metric does not improve beyond &#39;early_stopping_threshold&#39; for this many times of evaluation.
         * 
         * @return builder
         * 
         */
        public Builder earlyStoppingPatience(@Nullable Output<Integer> earlyStoppingPatience) {
            $.earlyStoppingPatience = earlyStoppingPatience;
            return this;
        }

        /**
         * @param earlyStoppingPatience Stop training if the loss metric does not improve beyond &#39;early_stopping_threshold&#39; for this many times of evaluation.
         * 
         * @return builder
         * 
         */
        public Builder earlyStoppingPatience(Integer earlyStoppingPatience) {
            return earlyStoppingPatience(Output.of(earlyStoppingPatience));
        }

        /**
         * @param earlyStoppingThreshold How much the loss must improve to prevent early stopping.
         * 
         * @return builder
         * 
         */
        public Builder earlyStoppingThreshold(@Nullable Output<Double> earlyStoppingThreshold) {
            $.earlyStoppingThreshold = earlyStoppingThreshold;
            return this;
        }

        /**
         * @param earlyStoppingThreshold How much the loss must improve to prevent early stopping.
         * 
         * @return builder
         * 
         */
        public Builder earlyStoppingThreshold(Double earlyStoppingThreshold) {
            return earlyStoppingThreshold(Output.of(earlyStoppingThreshold));
        }

        /**
         * @param learningRate The initial learning rate to be used during training
         * 
         * @return builder
         * 
         */
        public Builder learningRate(@Nullable Output<Double> learningRate) {
            $.learningRate = learningRate;
            return this;
        }

        /**
         * @param learningRate The initial learning rate to be used during training
         * 
         * @return builder
         * 
         */
        public Builder learningRate(Double learningRate) {
            return learningRate(Output.of(learningRate));
        }

        /**
         * @param logModelMetricsIntervalInSteps Determines how frequently to log model metrics.
         * 
         * Every step is logged for the first 20 steps and then follows this parameter for log frequency. Set to 0 to disable logging the model metrics.
         * 
         * @return builder
         * 
         */
        public Builder logModelMetricsIntervalInSteps(@Nullable Output<Integer> logModelMetricsIntervalInSteps) {
            $.logModelMetricsIntervalInSteps = logModelMetricsIntervalInSteps;
            return this;
        }

        /**
         * @param logModelMetricsIntervalInSteps Determines how frequently to log model metrics.
         * 
         * Every step is logged for the first 20 steps and then follows this parameter for log frequency. Set to 0 to disable logging the model metrics.
         * 
         * @return builder
         * 
         */
        public Builder logModelMetricsIntervalInSteps(Integer logModelMetricsIntervalInSteps) {
            return logModelMetricsIntervalInSteps(Output.of(logModelMetricsIntervalInSteps));
        }

        /**
         * @param loraAlpha This parameter represents the scaling factor for the weight matrices in LoRA.
         * 
         * @return builder
         * 
         */
        public Builder loraAlpha(@Nullable Output<Integer> loraAlpha) {
            $.loraAlpha = loraAlpha;
            return this;
        }

        /**
         * @param loraAlpha This parameter represents the scaling factor for the weight matrices in LoRA.
         * 
         * @return builder
         * 
         */
        public Builder loraAlpha(Integer loraAlpha) {
            return loraAlpha(Output.of(loraAlpha));
        }

        /**
         * @param loraDropout This parameter indicates the dropout probability for LoRA layers.
         * 
         * @return builder
         * 
         */
        public Builder loraDropout(@Nullable Output<Double> loraDropout) {
            $.loraDropout = loraDropout;
            return this;
        }

        /**
         * @param loraDropout This parameter indicates the dropout probability for LoRA layers.
         * 
         * @return builder
         * 
         */
        public Builder loraDropout(Double loraDropout) {
            return loraDropout(Output.of(loraDropout));
        }

        /**
         * @param loraR This parameter represents the LoRA rank of the update matrices.
         * 
         * @return builder
         * 
         */
        public Builder loraR(@Nullable Output<Integer> loraR) {
            $.loraR = loraR;
            return this;
        }

        /**
         * @param loraR This parameter represents the LoRA rank of the update matrices.
         * 
         * @return builder
         * 
         */
        public Builder loraR(Integer loraR) {
            return loraR(Output.of(loraR));
        }

        /**
         * @param numOfLastLayers The number of last layers to be fine-tuned.
         * 
         * @return builder
         * 
         */
        public Builder numOfLastLayers(@Nullable Output<Integer> numOfLastLayers) {
            $.numOfLastLayers = numOfLastLayers;
            return this;
        }

        /**
         * @param numOfLastLayers The number of last layers to be fine-tuned.
         * 
         * @return builder
         * 
         */
        public Builder numOfLastLayers(Integer numOfLastLayers) {
            return numOfLastLayers(Output.of(numOfLastLayers));
        }

        /**
         * @param totalTrainingEpochs The maximum number of training epochs to run for.
         * 
         * @return builder
         * 
         */
        public Builder totalTrainingEpochs(@Nullable Output<Integer> totalTrainingEpochs) {
            $.totalTrainingEpochs = totalTrainingEpochs;
            return this;
        }

        /**
         * @param totalTrainingEpochs The maximum number of training epochs to run for.
         * 
         * @return builder
         * 
         */
        public Builder totalTrainingEpochs(Integer totalTrainingEpochs) {
            return totalTrainingEpochs(Output.of(totalTrainingEpochs));
        }

        /**
         * @param trainingBatchSize The batch size used during training.
         * 
         * @return builder
         * 
         */
        public Builder trainingBatchSize(@Nullable Output<Integer> trainingBatchSize) {
            $.trainingBatchSize = trainingBatchSize;
            return this;
        }

        /**
         * @param trainingBatchSize The batch size used during training.
         * 
         * @return builder
         * 
         */
        public Builder trainingBatchSize(Integer trainingBatchSize) {
            return trainingBatchSize(Output.of(trainingBatchSize));
        }

        /**
         * @param trainingConfigType The fine-tuning method for training a custom model.
         * 
         * @return builder
         * 
         */
        public Builder trainingConfigType(Output<String> trainingConfigType) {
            $.trainingConfigType = trainingConfigType;
            return this;
        }

        /**
         * @param trainingConfigType The fine-tuning method for training a custom model.
         * 
         * @return builder
         * 
         */
        public Builder trainingConfigType(String trainingConfigType) {
            return trainingConfigType(Output.of(trainingConfigType));
        }

        public ModelFineTuneDetailsTrainingConfigArgs build() {
            if ($.trainingConfigType == null) {
                throw new MissingRequiredPropertyException("ModelFineTuneDetailsTrainingConfigArgs", "trainingConfigType");
            }
            return $;
        }
    }

}
