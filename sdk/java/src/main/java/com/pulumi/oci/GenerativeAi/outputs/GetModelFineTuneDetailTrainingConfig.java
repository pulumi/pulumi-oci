// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.oci.GenerativeAi.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.Objects;

@CustomType
public final class GetModelFineTuneDetailTrainingConfig {
    /**
     * @return Stop training if the loss metric does not improve beyond &#39;early_stopping_threshold&#39; for this many times of evaluation.
     * 
     */
    private Integer earlyStoppingPatience;
    /**
     * @return How much the loss must improve to prevent early stopping.
     * 
     */
    private Double earlyStoppingThreshold;
    /**
     * @return The initial learning rate to be used during training
     * 
     */
    private Double learningRate;
    /**
     * @return Determines how frequently to log model metrics.
     * 
     */
    private Integer logModelMetricsIntervalInSteps;
    /**
     * @return This parameter represents the scaling factor for the weight matrices in LoRA.
     * 
     */
    private Integer loraAlpha;
    /**
     * @return This parameter indicates the dropout probability for LoRA layers.
     * 
     */
    private Double loraDropout;
    /**
     * @return This parameter represents the LoRA rank of the update matrices.
     * 
     */
    private Integer loraR;
    /**
     * @return The number of last layers to be fine-tuned.
     * 
     */
    private Integer numOfLastLayers;
    /**
     * @return The maximum number of training epochs to run for.
     * 
     */
    private Integer totalTrainingEpochs;
    /**
     * @return The batch size used during training.
     * 
     */
    private Integer trainingBatchSize;
    /**
     * @return The fine-tuning method for training a custom model.
     * 
     */
    private String trainingConfigType;

    private GetModelFineTuneDetailTrainingConfig() {}
    /**
     * @return Stop training if the loss metric does not improve beyond &#39;early_stopping_threshold&#39; for this many times of evaluation.
     * 
     */
    public Integer earlyStoppingPatience() {
        return this.earlyStoppingPatience;
    }
    /**
     * @return How much the loss must improve to prevent early stopping.
     * 
     */
    public Double earlyStoppingThreshold() {
        return this.earlyStoppingThreshold;
    }
    /**
     * @return The initial learning rate to be used during training
     * 
     */
    public Double learningRate() {
        return this.learningRate;
    }
    /**
     * @return Determines how frequently to log model metrics.
     * 
     */
    public Integer logModelMetricsIntervalInSteps() {
        return this.logModelMetricsIntervalInSteps;
    }
    /**
     * @return This parameter represents the scaling factor for the weight matrices in LoRA.
     * 
     */
    public Integer loraAlpha() {
        return this.loraAlpha;
    }
    /**
     * @return This parameter indicates the dropout probability for LoRA layers.
     * 
     */
    public Double loraDropout() {
        return this.loraDropout;
    }
    /**
     * @return This parameter represents the LoRA rank of the update matrices.
     * 
     */
    public Integer loraR() {
        return this.loraR;
    }
    /**
     * @return The number of last layers to be fine-tuned.
     * 
     */
    public Integer numOfLastLayers() {
        return this.numOfLastLayers;
    }
    /**
     * @return The maximum number of training epochs to run for.
     * 
     */
    public Integer totalTrainingEpochs() {
        return this.totalTrainingEpochs;
    }
    /**
     * @return The batch size used during training.
     * 
     */
    public Integer trainingBatchSize() {
        return this.trainingBatchSize;
    }
    /**
     * @return The fine-tuning method for training a custom model.
     * 
     */
    public String trainingConfigType() {
        return this.trainingConfigType;
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(GetModelFineTuneDetailTrainingConfig defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private Integer earlyStoppingPatience;
        private Double earlyStoppingThreshold;
        private Double learningRate;
        private Integer logModelMetricsIntervalInSteps;
        private Integer loraAlpha;
        private Double loraDropout;
        private Integer loraR;
        private Integer numOfLastLayers;
        private Integer totalTrainingEpochs;
        private Integer trainingBatchSize;
        private String trainingConfigType;
        public Builder() {}
        public Builder(GetModelFineTuneDetailTrainingConfig defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.earlyStoppingPatience = defaults.earlyStoppingPatience;
    	      this.earlyStoppingThreshold = defaults.earlyStoppingThreshold;
    	      this.learningRate = defaults.learningRate;
    	      this.logModelMetricsIntervalInSteps = defaults.logModelMetricsIntervalInSteps;
    	      this.loraAlpha = defaults.loraAlpha;
    	      this.loraDropout = defaults.loraDropout;
    	      this.loraR = defaults.loraR;
    	      this.numOfLastLayers = defaults.numOfLastLayers;
    	      this.totalTrainingEpochs = defaults.totalTrainingEpochs;
    	      this.trainingBatchSize = defaults.trainingBatchSize;
    	      this.trainingConfigType = defaults.trainingConfigType;
        }

        @CustomType.Setter
        public Builder earlyStoppingPatience(Integer earlyStoppingPatience) {
            if (earlyStoppingPatience == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "earlyStoppingPatience");
            }
            this.earlyStoppingPatience = earlyStoppingPatience;
            return this;
        }
        @CustomType.Setter
        public Builder earlyStoppingThreshold(Double earlyStoppingThreshold) {
            if (earlyStoppingThreshold == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "earlyStoppingThreshold");
            }
            this.earlyStoppingThreshold = earlyStoppingThreshold;
            return this;
        }
        @CustomType.Setter
        public Builder learningRate(Double learningRate) {
            if (learningRate == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "learningRate");
            }
            this.learningRate = learningRate;
            return this;
        }
        @CustomType.Setter
        public Builder logModelMetricsIntervalInSteps(Integer logModelMetricsIntervalInSteps) {
            if (logModelMetricsIntervalInSteps == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "logModelMetricsIntervalInSteps");
            }
            this.logModelMetricsIntervalInSteps = logModelMetricsIntervalInSteps;
            return this;
        }
        @CustomType.Setter
        public Builder loraAlpha(Integer loraAlpha) {
            if (loraAlpha == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "loraAlpha");
            }
            this.loraAlpha = loraAlpha;
            return this;
        }
        @CustomType.Setter
        public Builder loraDropout(Double loraDropout) {
            if (loraDropout == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "loraDropout");
            }
            this.loraDropout = loraDropout;
            return this;
        }
        @CustomType.Setter
        public Builder loraR(Integer loraR) {
            if (loraR == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "loraR");
            }
            this.loraR = loraR;
            return this;
        }
        @CustomType.Setter
        public Builder numOfLastLayers(Integer numOfLastLayers) {
            if (numOfLastLayers == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "numOfLastLayers");
            }
            this.numOfLastLayers = numOfLastLayers;
            return this;
        }
        @CustomType.Setter
        public Builder totalTrainingEpochs(Integer totalTrainingEpochs) {
            if (totalTrainingEpochs == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "totalTrainingEpochs");
            }
            this.totalTrainingEpochs = totalTrainingEpochs;
            return this;
        }
        @CustomType.Setter
        public Builder trainingBatchSize(Integer trainingBatchSize) {
            if (trainingBatchSize == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "trainingBatchSize");
            }
            this.trainingBatchSize = trainingBatchSize;
            return this;
        }
        @CustomType.Setter
        public Builder trainingConfigType(String trainingConfigType) {
            if (trainingConfigType == null) {
              throw new MissingRequiredPropertyException("GetModelFineTuneDetailTrainingConfig", "trainingConfigType");
            }
            this.trainingConfigType = trainingConfigType;
            return this;
        }
        public GetModelFineTuneDetailTrainingConfig build() {
            final var _resultValue = new GetModelFineTuneDetailTrainingConfig();
            _resultValue.earlyStoppingPatience = earlyStoppingPatience;
            _resultValue.earlyStoppingThreshold = earlyStoppingThreshold;
            _resultValue.learningRate = learningRate;
            _resultValue.logModelMetricsIntervalInSteps = logModelMetricsIntervalInSteps;
            _resultValue.loraAlpha = loraAlpha;
            _resultValue.loraDropout = loraDropout;
            _resultValue.loraR = loraR;
            _resultValue.numOfLastLayers = numOfLastLayers;
            _resultValue.totalTrainingEpochs = totalTrainingEpochs;
            _resultValue.trainingBatchSize = trainingBatchSize;
            _resultValue.trainingConfigType = trainingConfigType;
            return _resultValue;
        }
    }
}
