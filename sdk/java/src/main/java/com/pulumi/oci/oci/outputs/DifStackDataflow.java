// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.oci.oci.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import com.pulumi.oci.oci.outputs.DifStackDataflowConnections;
import com.pulumi.oci.oci.outputs.DifStackDataflowDriverShapeConfig;
import com.pulumi.oci.oci.outputs.DifStackDataflowExecutorShapeConfig;
import java.lang.Integer;
import java.lang.String;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class DifStackDataflow {
    /**
     * @return Contains the archive from object storage bucket which can be added as dependency to data flow application.
     * 
     */
    private @Nullable String archiveUri;
    /**
     * @return (Updatable) Details for connections to other services from Dataflow.
     * 
     */
    private @Nullable DifStackDataflowConnections connections;
    /**
     * @return (Updatable) The VM shape for the driver. Sets the driver cores and memory.
     * 
     */
    private String driverShape;
    /**
     * @return (Updatable) This is used to configure the shape of the driver or executor if a flexible shape is used.
     * 
     */
    private @Nullable DifStackDataflowDriverShapeConfig driverShapeConfig;
    /**
     * @return Contains the main file (py/jar) along with parameters &amp; configuration to be passed to the DataFlow run.
     * 
     */
    private @Nullable String execute;
    /**
     * @return (Updatable) The VM shape for the executors. Sets the executor cores and memory.
     * 
     */
    private String executorShape;
    /**
     * @return (Updatable) This is used to configure the shape of the driver or executor if a flexible shape is used.
     * 
     */
    private @Nullable DifStackDataflowExecutorShapeConfig executorShapeConfig;
    /**
     * @return Id for dataflow instance
     * 
     */
    private String instanceId;
    /**
     * @return (Updatable) InstanceId of log bucket created as part of objectstorage service in stack. Used for storing application run logs.
     * 
     */
    private String logBucketInstanceId;
    /**
     * @return (Updatable) The number of executor VMs requested.
     * 
     */
    private Integer numExecutors;
    /**
     * @return (Updatable) OCID of the already provisioned dataflow private endpoint.
     * 
     */
    private @Nullable String privateEndpointId;
    /**
     * @return (Updatable) The Spark version utilized to run the application.
     * 
     */
    private String sparkVersion;
    /**
     * @return (Updatable) InstanceId of warehouse bucket created as part of objectstorage service in stack. Mandatory for SQL applications.
     * 
     */
    private @Nullable String warehouseBucketInstanceId;

    private DifStackDataflow() {}
    /**
     * @return Contains the archive from object storage bucket which can be added as dependency to data flow application.
     * 
     */
    public Optional<String> archiveUri() {
        return Optional.ofNullable(this.archiveUri);
    }
    /**
     * @return (Updatable) Details for connections to other services from Dataflow.
     * 
     */
    public Optional<DifStackDataflowConnections> connections() {
        return Optional.ofNullable(this.connections);
    }
    /**
     * @return (Updatable) The VM shape for the driver. Sets the driver cores and memory.
     * 
     */
    public String driverShape() {
        return this.driverShape;
    }
    /**
     * @return (Updatable) This is used to configure the shape of the driver or executor if a flexible shape is used.
     * 
     */
    public Optional<DifStackDataflowDriverShapeConfig> driverShapeConfig() {
        return Optional.ofNullable(this.driverShapeConfig);
    }
    /**
     * @return Contains the main file (py/jar) along with parameters &amp; configuration to be passed to the DataFlow run.
     * 
     */
    public Optional<String> execute() {
        return Optional.ofNullable(this.execute);
    }
    /**
     * @return (Updatable) The VM shape for the executors. Sets the executor cores and memory.
     * 
     */
    public String executorShape() {
        return this.executorShape;
    }
    /**
     * @return (Updatable) This is used to configure the shape of the driver or executor if a flexible shape is used.
     * 
     */
    public Optional<DifStackDataflowExecutorShapeConfig> executorShapeConfig() {
        return Optional.ofNullable(this.executorShapeConfig);
    }
    /**
     * @return Id for dataflow instance
     * 
     */
    public String instanceId() {
        return this.instanceId;
    }
    /**
     * @return (Updatable) InstanceId of log bucket created as part of objectstorage service in stack. Used for storing application run logs.
     * 
     */
    public String logBucketInstanceId() {
        return this.logBucketInstanceId;
    }
    /**
     * @return (Updatable) The number of executor VMs requested.
     * 
     */
    public Integer numExecutors() {
        return this.numExecutors;
    }
    /**
     * @return (Updatable) OCID of the already provisioned dataflow private endpoint.
     * 
     */
    public Optional<String> privateEndpointId() {
        return Optional.ofNullable(this.privateEndpointId);
    }
    /**
     * @return (Updatable) The Spark version utilized to run the application.
     * 
     */
    public String sparkVersion() {
        return this.sparkVersion;
    }
    /**
     * @return (Updatable) InstanceId of warehouse bucket created as part of objectstorage service in stack. Mandatory for SQL applications.
     * 
     */
    public Optional<String> warehouseBucketInstanceId() {
        return Optional.ofNullable(this.warehouseBucketInstanceId);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(DifStackDataflow defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable String archiveUri;
        private @Nullable DifStackDataflowConnections connections;
        private String driverShape;
        private @Nullable DifStackDataflowDriverShapeConfig driverShapeConfig;
        private @Nullable String execute;
        private String executorShape;
        private @Nullable DifStackDataflowExecutorShapeConfig executorShapeConfig;
        private String instanceId;
        private String logBucketInstanceId;
        private Integer numExecutors;
        private @Nullable String privateEndpointId;
        private String sparkVersion;
        private @Nullable String warehouseBucketInstanceId;
        public Builder() {}
        public Builder(DifStackDataflow defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.archiveUri = defaults.archiveUri;
    	      this.connections = defaults.connections;
    	      this.driverShape = defaults.driverShape;
    	      this.driverShapeConfig = defaults.driverShapeConfig;
    	      this.execute = defaults.execute;
    	      this.executorShape = defaults.executorShape;
    	      this.executorShapeConfig = defaults.executorShapeConfig;
    	      this.instanceId = defaults.instanceId;
    	      this.logBucketInstanceId = defaults.logBucketInstanceId;
    	      this.numExecutors = defaults.numExecutors;
    	      this.privateEndpointId = defaults.privateEndpointId;
    	      this.sparkVersion = defaults.sparkVersion;
    	      this.warehouseBucketInstanceId = defaults.warehouseBucketInstanceId;
        }

        @CustomType.Setter
        public Builder archiveUri(@Nullable String archiveUri) {

            this.archiveUri = archiveUri;
            return this;
        }
        @CustomType.Setter
        public Builder connections(@Nullable DifStackDataflowConnections connections) {

            this.connections = connections;
            return this;
        }
        @CustomType.Setter
        public Builder driverShape(String driverShape) {
            if (driverShape == null) {
              throw new MissingRequiredPropertyException("DifStackDataflow", "driverShape");
            }
            this.driverShape = driverShape;
            return this;
        }
        @CustomType.Setter
        public Builder driverShapeConfig(@Nullable DifStackDataflowDriverShapeConfig driverShapeConfig) {

            this.driverShapeConfig = driverShapeConfig;
            return this;
        }
        @CustomType.Setter
        public Builder execute(@Nullable String execute) {

            this.execute = execute;
            return this;
        }
        @CustomType.Setter
        public Builder executorShape(String executorShape) {
            if (executorShape == null) {
              throw new MissingRequiredPropertyException("DifStackDataflow", "executorShape");
            }
            this.executorShape = executorShape;
            return this;
        }
        @CustomType.Setter
        public Builder executorShapeConfig(@Nullable DifStackDataflowExecutorShapeConfig executorShapeConfig) {

            this.executorShapeConfig = executorShapeConfig;
            return this;
        }
        @CustomType.Setter
        public Builder instanceId(String instanceId) {
            if (instanceId == null) {
              throw new MissingRequiredPropertyException("DifStackDataflow", "instanceId");
            }
            this.instanceId = instanceId;
            return this;
        }
        @CustomType.Setter
        public Builder logBucketInstanceId(String logBucketInstanceId) {
            if (logBucketInstanceId == null) {
              throw new MissingRequiredPropertyException("DifStackDataflow", "logBucketInstanceId");
            }
            this.logBucketInstanceId = logBucketInstanceId;
            return this;
        }
        @CustomType.Setter
        public Builder numExecutors(Integer numExecutors) {
            if (numExecutors == null) {
              throw new MissingRequiredPropertyException("DifStackDataflow", "numExecutors");
            }
            this.numExecutors = numExecutors;
            return this;
        }
        @CustomType.Setter
        public Builder privateEndpointId(@Nullable String privateEndpointId) {

            this.privateEndpointId = privateEndpointId;
            return this;
        }
        @CustomType.Setter
        public Builder sparkVersion(String sparkVersion) {
            if (sparkVersion == null) {
              throw new MissingRequiredPropertyException("DifStackDataflow", "sparkVersion");
            }
            this.sparkVersion = sparkVersion;
            return this;
        }
        @CustomType.Setter
        public Builder warehouseBucketInstanceId(@Nullable String warehouseBucketInstanceId) {

            this.warehouseBucketInstanceId = warehouseBucketInstanceId;
            return this;
        }
        public DifStackDataflow build() {
            final var _resultValue = new DifStackDataflow();
            _resultValue.archiveUri = archiveUri;
            _resultValue.connections = connections;
            _resultValue.driverShape = driverShape;
            _resultValue.driverShapeConfig = driverShapeConfig;
            _resultValue.execute = execute;
            _resultValue.executorShape = executorShape;
            _resultValue.executorShapeConfig = executorShapeConfig;
            _resultValue.instanceId = instanceId;
            _resultValue.logBucketInstanceId = logBucketInstanceId;
            _resultValue.numExecutors = numExecutors;
            _resultValue.privateEndpointId = privateEndpointId;
            _resultValue.sparkVersion = sparkVersion;
            _resultValue.warehouseBucketInstanceId = warehouseBucketInstanceId;
            return _resultValue;
        }
    }
}
