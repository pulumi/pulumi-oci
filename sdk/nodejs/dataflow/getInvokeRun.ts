// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import { input as inputs, output as outputs } from "../types";
import * as utilities from "../utilities";

/**
 * This data source provides details about a specific Invoke Run resource in Oracle Cloud Infrastructure Data Flow service.
 *
 * Retrieves the run for the specified `runId`.
 *
 * ## Example Usage
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as oci from "@pulumi/oci";
 *
 * const testInvokeRun = oci.DataFlow.getInvokeRun({
 *     runId: oci_dataflow_run.test_run.id,
 * });
 * ```
 */
export function getInvokeRun(args: GetInvokeRunArgs, opts?: pulumi.InvokeOptions): Promise<GetInvokeRunResult> {
    if (!opts) {
        opts = {}
    }

    opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
    return pulumi.runtime.invoke("oci:DataFlow/getInvokeRun:getInvokeRun", {
        "runId": args.runId,
    }, opts);
}

/**
 * A collection of arguments for invoking getInvokeRun.
 */
export interface GetInvokeRunArgs {
    /**
     * The unique ID for the run
     */
    runId: string;
}

/**
 * A collection of values returned by getInvokeRun.
 */
export interface GetInvokeRunResult {
    /**
     * The application ID.
     */
    readonly applicationId: string;
    /**
     * An Oracle Cloud Infrastructure URI of an archive.zip file containing custom dependencies that may be used to support the execution a Python, Java, or Scala application. See https://docs.cloud.oracle.com/iaas/Content/API/SDKDocs/hdfsconnector.htm#uriformat.
     */
    readonly archiveUri: string;
    /**
     * The arguments passed to the running application as command line arguments.  An argument is either a plain text or a placeholder. Placeholders are replaced using values from the parameters map.  Each placeholder specified must be represented in the parameters map else the request (POST or PUT) will fail with a HTTP 400 status code.  Placeholders are specified as `Service Api Spec`, where `name` is the name of the parameter. Example:  `[ "--input", "${input_file}", "--name", "John Doe" ]` If "inputFile" has a value of "mydata.xml", then the value above will be translated to `--input mydata.xml --name "John Doe"`
     */
    readonly arguments: string[];
    readonly asynchronous: boolean;
    /**
     * The class for the application.
     */
    readonly className: string;
    /**
     * The OCID of a compartment.
     */
    readonly compartmentId: string;
    /**
     * The Spark configuration passed to the running process. See https://spark.apache.org/docs/latest/configuration.html#available-properties. Example: { "spark.app.name" : "My App Name", "spark.shuffle.io.maxRetries" : "4" } Note: Not all Spark properties are permitted to be set.  Attempting to set a property that is not allowed to be overwritten will cause a 400 status to be returned.
     */
    readonly configuration: {[key: string]: any};
    /**
     * The data read by the run in bytes.
     */
    readonly dataReadInBytes: string;
    /**
     * The data written by the run in bytes.
     */
    readonly dataWrittenInBytes: string;
    /**
     * Defined tags for this resource. Each key is predefined and scoped to a namespace. For more information, see [Resource Tags](https://docs.cloud.oracle.com/iaas/Content/General/Concepts/resourcetags.htm). Example: `{"Operations.CostCenter": "42"}`
     */
    readonly definedTags: {[key: string]: any};
    /**
     * A user-friendly name. This name is not necessarily unique.
     */
    readonly displayName: string;
    /**
     * The VM shape for the driver. Sets the driver cores and memory.
     */
    readonly driverShape: string;
    /**
     * This is used to configure the shape of the driver or executor if a flexible shape is used.
     */
    readonly driverShapeConfigs: outputs.DataFlow.GetInvokeRunDriverShapeConfig[];
    /**
     * The input used for spark-submit command. For more details see https://spark.apache.org/docs/latest/submitting-applications.html#launching-applications-with-spark-submit. Supported options include ``--class``, ``--file``, ``--jars``, ``--conf``, ``--py-files``, and main application file with arguments. Example: ``--jars oci://path/to/a.jar,oci://path/to/b.jar --files oci://path/to/a.json,oci://path/to/b.csv --py-files oci://path/to/a.py,oci://path/to/b.py --conf spark.sql.crossJoin.enabled=true --class org.apache.spark.examples.SparkPi oci://path/to/main.jar 10`` Note: If execute is specified together with applicationId, className, configuration, fileUri, language, arguments, parameters during application create/update, or run create/submit, Data Flow service will use derived information from execute input only.
     */
    readonly execute: string;
    /**
     * The VM shape for the executors. Sets the executor cores and memory.
     */
    readonly executorShape: string;
    /**
     * This is used to configure the shape of the driver or executor if a flexible shape is used.
     */
    readonly executorShapeConfigs: outputs.DataFlow.GetInvokeRunExecutorShapeConfig[];
    /**
     * An Oracle Cloud Infrastructure URI of the file containing the application to execute. See https://docs.cloud.oracle.com/iaas/Content/API/SDKDocs/hdfsconnector.htm#uriformat.
     */
    readonly fileUri: string;
    /**
     * Free-form tags for this resource. Each tag is a simple key-value pair with no predefined name, type, or namespace. For more information, see [Resource Tags](https://docs.cloud.oracle.com/iaas/Content/General/Concepts/resourcetags.htm). Example: `{"Department": "Finance"}`
     */
    readonly freeformTags: {[key: string]: any};
    /**
     * The ID of a run.
     */
    readonly id: string;
    /**
     * The Spark language.
     */
    readonly language: string;
    /**
     * The detailed messages about the lifecycle state.
     */
    readonly lifecycleDetails: string;
    /**
     * An Oracle Cloud Infrastructure URI of the bucket where the Spark job logs are to be uploaded. See https://docs.cloud.oracle.com/iaas/Content/API/SDKDocs/hdfsconnector.htm#uriformat.
     */
    readonly logsBucketUri: string;
    /**
     * The OCID of Oracle Cloud Infrastructure Hive Metastore.
     */
    readonly metastoreId: string;
    /**
     * The number of executor VMs requested.
     */
    readonly numExecutors: number;
    /**
     * Unique Oracle assigned identifier for the request. If you need to contact Oracle about a particular request, please provide the request ID.
     */
    readonly opcRequestId: string;
    /**
     * The OCID of the user who created the resource.
     */
    readonly ownerPrincipalId: string;
    /**
     * The username of the user who created the resource.  If the username of the owner does not exist, `null` will be returned and the caller should refer to the ownerPrincipalId value instead.
     */
    readonly ownerUserName: string;
    /**
     * An array of name/value pairs used to fill placeholders found in properties like `Application.arguments`.  The name must be a string of one or more word characters (a-z, A-Z, 0-9, _).  The value can be a string of 0 or more characters of any kind. Example:  [ { name: "iterations", value: "10"}, { name: "inputFile", value: "mydata.xml" }, { name: "variableX", value: "${x}"} ]
     */
    readonly parameters: outputs.DataFlow.GetInvokeRunParameter[];
    /**
     * An array of DNS zone names. Example: `[ "app.examplecorp.com", "app.examplecorp2.com" ]`
     */
    readonly privateEndpointDnsZones: string[];
    /**
     * The OCID of a private endpoint.
     */
    readonly privateEndpointId: string;
    /**
     * The maximum number of hosts to be accessed through the private endpoint. This value is used to calculate the relevant CIDR block and should be a multiple of 256.  If the value is not a multiple of 256, it is rounded up to the next multiple of 256. For example, 300 is rounded up to 512.
     */
    readonly privateEndpointMaxHostCount: number;
    /**
     * An array of network security group OCIDs.
     */
    readonly privateEndpointNsgIds: string[];
    /**
     * The OCID of a subnet.
     */
    readonly privateEndpointSubnetId: string;
    /**
     * The duration of the run in milliseconds.
     */
    readonly runDurationInMilliseconds: string;
    readonly runId: string;
    /**
     * The Spark version utilized to run the application.
     */
    readonly sparkVersion: string;
    /**
     * The current state of this run.
     */
    readonly state: string;
    /**
     * The date and time a application was created, expressed in [RFC 3339](https://tools.ietf.org/html/rfc3339) timestamp format. Example: `2018-04-03T21:10:29.600Z`
     */
    readonly timeCreated: string;
    /**
     * The date and time a application was updated, expressed in [RFC 3339](https://tools.ietf.org/html/rfc3339) timestamp format. Example: `2018-04-03T21:10:29.600Z`
     */
    readonly timeUpdated: string;
    /**
     * The total number of oCPU requested by the run.
     */
    readonly totalOcpu: number;
    /**
     * The Spark application processing type.
     */
    readonly type: string;
    /**
     * An Oracle Cloud Infrastructure URI of the bucket to be used as default warehouse directory for BATCH SQL runs. See https://docs.cloud.oracle.com/iaas/Content/API/SDKDocs/hdfsconnector.htm#uriformat.
     */
    readonly warehouseBucketUri: string;
}

export function getInvokeRunOutput(args: GetInvokeRunOutputArgs, opts?: pulumi.InvokeOptions): pulumi.Output<GetInvokeRunResult> {
    return pulumi.output(args).apply(a => getInvokeRun(a, opts))
}

/**
 * A collection of arguments for invoking getInvokeRun.
 */
export interface GetInvokeRunOutputArgs {
    /**
     * The unique ID for the run
     */
    runId: pulumi.Input<string>;
}
